{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News_Stock.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMRZv5yC-XbX",
        "outputId": "bfe7f701-bb3f-4fa7-f4ee-4756007b1d8d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords, LazyCorpusLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8P-uWnj-bvB"
      },
      "source": [
        "df = pd.read_csv('news _stock.csv', encoding = 'ISO-8859-1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "ECm86567--tZ",
        "outputId": "df36287d-1a44-43fd-bea5-ecf95cacc2b9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Label</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>0</td>\n",
              "      <td>A 'hindrance to operations': extracts from the...</td>\n",
              "      <td>Scorecard</td>\n",
              "      <td>Hughes' instant hit buoys Blues</td>\n",
              "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
              "      <td>Chaos as Maracana builds up for United</td>\n",
              "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
              "      <td>Hungry Spurs sense rich pickings</td>\n",
              "      <td>Gunners so wide of an easy target</td>\n",
              "      <td>Derby raise a glass to Strupar's debut double</td>\n",
              "      <td>Southgate strikes, Leeds pay the penalty</td>\n",
              "      <td>Hammers hand Robson a youthful lesson</td>\n",
              "      <td>Saints party like it's 1999</td>\n",
              "      <td>Wear wolves have turned into lambs</td>\n",
              "      <td>Stump mike catches testy Gough's taunt</td>\n",
              "      <td>Langer escapes to hit 167</td>\n",
              "      <td>Flintoff injury piles on woe for England</td>\n",
              "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
              "      <td>Kohl's successor drawn into scandal</td>\n",
              "      <td>The difference between men and women</td>\n",
              "      <td>Sara Denver, nurse turned solicitor</td>\n",
              "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
              "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
              "      <td>Russian roulette</td>\n",
              "      <td>Sold out</td>\n",
              "      <td>Recovering a title</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>0</td>\n",
              "      <td>Scorecard</td>\n",
              "      <td>The best lake scene</td>\n",
              "      <td>Leader: German sleaze inquiry</td>\n",
              "      <td>Cheerio, boyo</td>\n",
              "      <td>The main recommendations</td>\n",
              "      <td>Has Cubie killed fees?</td>\n",
              "      <td>Has Cubie killed fees?</td>\n",
              "      <td>Has Cubie killed fees?</td>\n",
              "      <td>Hopkins 'furious' at Foster's lack of Hannibal...</td>\n",
              "      <td>Has Cubie killed fees?</td>\n",
              "      <td>A tale of two tails</td>\n",
              "      <td>I say what I like and I like what I say</td>\n",
              "      <td>Elbows, Eyes and Nipples</td>\n",
              "      <td>Task force to assess risk of asteroid collision</td>\n",
              "      <td>How I found myself at last</td>\n",
              "      <td>On the critical list</td>\n",
              "      <td>The timing of their lives</td>\n",
              "      <td>Dear doctor</td>\n",
              "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
              "      <td>Burundi peace initiative fades after rebels re...</td>\n",
              "      <td>PE points the way forward to the ECB</td>\n",
              "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
              "      <td>Jane Ratcliffe</td>\n",
              "      <td>Yet more things you wouldn't know without the ...</td>\n",
              "      <td>Millennium bug fails to bite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>0</td>\n",
              "      <td>Coventry caught on counter by Flo</td>\n",
              "      <td>United's rivals on the road to Rio</td>\n",
              "      <td>Thatcher issues defence before trial by video</td>\n",
              "      <td>Police help Smith lay down the law at Everton</td>\n",
              "      <td>Tale of Trautmann bears two more retellings</td>\n",
              "      <td>England on the rack</td>\n",
              "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
              "      <td>Cullinan continues his Cape monopoly</td>\n",
              "      <td>McGrath puts India out of their misery</td>\n",
              "      <td>Blair Witch bandwagon rolls on</td>\n",
              "      <td>Pele turns up heat on Ferguson</td>\n",
              "      <td>Party divided over Kohl slush fund scandal</td>\n",
              "      <td>Manchester United (England)</td>\n",
              "      <td>Women in record South Pole walk</td>\n",
              "      <td>Vasco da Gama (Brazil)</td>\n",
              "      <td>South Melbourne (Australia)</td>\n",
              "      <td>Necaxa (Mexico)</td>\n",
              "      <td>Real Madrid (Spain)</td>\n",
              "      <td>Raja Casablanca (Morocco)</td>\n",
              "      <td>Corinthians (Brazil)</td>\n",
              "      <td>Tony's pet project</td>\n",
              "      <td>Al Nassr (Saudi Arabia)</td>\n",
              "      <td>Ideal Holmes show</td>\n",
              "      <td>Pinochet leaves hospital after tests</td>\n",
              "      <td>Useful links</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-06</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilgrim knows how to progress</td>\n",
              "      <td>Thatcher facing ban</td>\n",
              "      <td>McIlroy calls for Irish fighting spirit</td>\n",
              "      <td>Leicester bin stadium blueprint</td>\n",
              "      <td>United braced for Mexican wave</td>\n",
              "      <td>Auntie back in fashion, even if the dress look...</td>\n",
              "      <td>Shoaib appeal goes to the top</td>\n",
              "      <td>Hussain hurt by 'shambles' but lays blame on e...</td>\n",
              "      <td>England's decade of disasters</td>\n",
              "      <td>Revenge is sweet for jubilant Cronje</td>\n",
              "      <td>Our choice, not theirs</td>\n",
              "      <td>Profile of former US Nazi Party officer Willia...</td>\n",
              "      <td>New evidence shows record of war crimes suspec...</td>\n",
              "      <td>The rise of the supernerds</td>\n",
              "      <td>Written on the body</td>\n",
              "      <td>Putin admits Yeltsin quit to give him a head s...</td>\n",
              "      <td>BBC worst hit as digital TV begins to bite</td>\n",
              "      <td>How much can you pay for...</td>\n",
              "      <td>Christmas glitches</td>\n",
              "      <td>Upending a table, Chopping a line and Scoring ...</td>\n",
              "      <td>Scientific evidence 'unreliable', defence claims</td>\n",
              "      <td>Fusco wins judicial review in extradition case</td>\n",
              "      <td>Rebels thwart Russian advance</td>\n",
              "      <td>Blair orders shake-up of failing NHS</td>\n",
              "      <td>Lessons of law's hard heart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-07</td>\n",
              "      <td>1</td>\n",
              "      <td>Hitches and Horlocks</td>\n",
              "      <td>Beckham off but United survive</td>\n",
              "      <td>Breast cancer screening</td>\n",
              "      <td>Alan Parker</td>\n",
              "      <td>Guardian readers: are you all whingers?</td>\n",
              "      <td>Hollywood Beyond</td>\n",
              "      <td>Ashes and diamonds</td>\n",
              "      <td>Whingers - a formidable minority</td>\n",
              "      <td>Alan Parker - part two</td>\n",
              "      <td>Thuggery, Toxins and Ties</td>\n",
              "      <td>Met faces fresh attack on race crime</td>\n",
              "      <td>Everton fans top racist 'league of shame'</td>\n",
              "      <td>Our breasts, ourselves</td>\n",
              "      <td>Russia's new boss has an extremely strange his...</td>\n",
              "      <td>Always and forever</td>\n",
              "      <td>Most everywhere:  UDIs</td>\n",
              "      <td>Most wanted:  Chloe lunettes</td>\n",
              "      <td>Return of the cane 'completely off the agenda'</td>\n",
              "      <td>From Sleepy Hollow to Greeneland</td>\n",
              "      <td>Blunkett outlines vision for over 11s</td>\n",
              "      <td>Embattled Dobson attacks 'play now, pay later'...</td>\n",
              "      <td>Doom and the Dome</td>\n",
              "      <td>What is the north-south divide?</td>\n",
              "      <td>Aitken released from jail</td>\n",
              "      <td>Gone aloft</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  ...                         Top25\n",
              "0  2000-01-03  ...            Recovering a title\n",
              "1  2000-01-04  ...  Millennium bug fails to bite\n",
              "2  2000-01-05  ...                  Useful links\n",
              "3  2000-01-06  ...   Lessons of law's hard heart\n",
              "4  2000-01-07  ...                    Gone aloft\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpuuuDSV_AvO"
      },
      "source": [
        "X = df.drop('Label', axis = 1)\n",
        "y = df['Label']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSvJdxl2_FSq"
      },
      "source": [
        "input_data = []\n",
        "for i in range(len(X.index)):\n",
        "    input_data.append(' '.join(str(x) for x in X.iloc[i,2:27]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMn5Gr6G_Ljp"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = stopwords.words('english')  \n",
        "for i in range(len(input_data)):\n",
        "    input_data[i] = input_data[i].lower()\n",
        "    input_data[i] = re.sub('[^A-Za-z]', ' ', input_data[i])\n",
        "    input_data[i] = nltk.word_tokenize(input_data[i])\n",
        "    input_data[i] = [lemmatizer.lemmatize(word) for word in input_data[i] if word not in set(stop_words)]\n",
        "    input_data[i] = ' '.join(input_data[i])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zGe0eu_Bz9u"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_RFWbqxHZl8"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range= (1,1))\n",
        "transformed_train = vectorizer.fit_transform(input_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrM9ofhxAX5U"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( transformed_train, y, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKf_tO9UE1I1"
      },
      "source": [
        "random_forest = RandomForestClassifier(n_estimators= 200, criterion = 'entropy')\n",
        "model = random_forest.fit(X_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJvWIZNqGy8L",
        "outputId": "9bd4970d-03ea-4ad6-fa74-356f2cf902a5"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "score = model.score(X_test,y_test)\n",
        "score"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5109666937449229"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y30j2XWlG6FZ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR8HjJd-Iy2N",
        "outputId": "4b9581e6-f25d-448c-be5b-e1cf9a4dafe0"
      },
      "source": [
        "matrix = confusion_matrix(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "score = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(matrix)\n",
        "print(score)\n",
        "print(report)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[160 411]\n",
            " [191 469]]\n",
            "0.5109666937449229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.28      0.35       571\n",
            "           1       0.53      0.71      0.61       660\n",
            "\n",
            "    accuracy                           0.51      1231\n",
            "   macro avg       0.49      0.50      0.48      1231\n",
            "weighted avg       0.50      0.51      0.49      1231\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElGJY7weQp_7"
      },
      "source": [
        "The model has only an accuracy of 50%, but it does not overfit the data, and does the job."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc5Auqw1KbX4"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}